# ğŸŸ¢ DACON ë‹¹ë‡¨ë³‘ ì˜ˆì¸¡ ëŒ€íšŒ: ì´ì§„ ë¶„ë¥˜ ë¬¸ì œ (Outcome = 0 or 1)

import numpy as np
import pandas as pd
import time
import tensorflow as tf

from keras.models import Sequential
from keras.layers import Dense, BatchNormalization, Dropout, Conv1D, Flatten
from keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_auc_score, classification_report

# 1. ë°ì´í„° ë¡œë”©
path = '/workspace/TensorJae/Study25/_data/diabetes/'
train_csv = pd.read_csv(path + 'train.csv', index_col=0)
test_csv = pd.read_csv(path + 'test.csv', index_col=0)
sample_submission_csv = pd.read_csv(path + 'sample_submission.csv', index_col=0)

# 2. í”¼ì²˜/íƒ€ê²Ÿ ë¶„ë¦¬ ë° ì „ì²˜ë¦¬
x = train_csv.drop(['Outcome'], axis=1)
y = train_csv['Outcome']

# 0ì„ NaNìœ¼ë¡œ ì²˜ë¦¬ í›„ í‰ê· ê°’ ëŒ€ì²´
x = x.replace(0, np.nan)
x = x.fillna(train_csv.mean())

# 3. ë°ì´í„° ë¶„í• 
x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=33)

# 4. ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

# 5. reshape for Conv1D
x_train = x_train.reshape(-1, 8, 1)
x_test = x_test.reshape(-1, 8, 1)

# 6. ëª¨ë¸ êµ¬ì„±
model = Sequential([
    Conv1D(filters=64, kernel_size=2, padding='same', input_shape=(8, 1), activation='relu'),
    Conv1D(filters=64, kernel_size=2, activation='relu'),
    Conv1D(filters=64, kernel_size=2, activation='relu'),
    Flatten(),
    Dense(64, activation='relu'),
    BatchNormalization(),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')  # âœ… ì´ì§„ ë¶„ë¥˜ â†’ sigmoid
])

model.summary()

# 7. ì»´íŒŒì¼
model.compile(
    loss='binary_crossentropy',
    optimizer='adam',
    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]
)

# 8. ì½œë°±
es = EarlyStopping(
    monitor='val_loss',
    patience=15,
    mode='min',
    verbose=1,
    restore_best_weights=True
)

# 9. í•™ìŠµ
start = time.time()
hist = model.fit(
    x_train, y_train,
    epochs=200,
    batch_size=32,
    validation_split=0.2,
    verbose=1,
    callbacks=[es]
)
end = time.time()

# 10. í‰ê°€ ë° ì˜ˆì¸¡
loss, acc, auc = model.evaluate(x_test, y_test, verbose=0)
y_pred_prob = model.predict(x_test)
y_pred_class = (y_pred_prob >= 0.5).astype(int)

# 11. ì¶”ê°€ ì§€í‘œ
roc_auc = roc_auc_score(y_test, y_pred_prob)

# 12. ê²°ê³¼ ì¶œë ¥
print("\nğŸ“Š Final Evaluation Metrics:")
print(f"âœ… Binary Crossentropy Loss : {loss:.4f}")
print(f"âœ… Accuracy                 : {acc:.4f}")
print(f"âœ… Keras AUC                : {auc:.4f}")
print(f"âœ… Sklearn ROC AUC          : {roc_auc:.4f}")
print(f"â±ï¸ Training Time            : {end - start:.2f} seconds")

print("\nğŸ“„ Classification Report:")
print(classification_report(y_test, y_pred_class))



# ğŸ“Š Final Evaluation Metrics:
# âœ… Binary Crossentropy Loss : 0.5079
# âœ… Accuracy                 : 0.7252
# âœ… Keras AUC                : 0.7754
# âœ… Sklearn ROC AUC          : 0.7751
# â±ï¸ Training Time            : 13.90 seconds

# ğŸ“„ Classification Report:
#               precision    recall  f1-score   support

#            0       0.75      0.90      0.82        92
#            1       0.57      0.31      0.40        39

#     accuracy                           0.73       131
#    macro avg       0.66      0.60      0.61       131
# weighted avg       0.70      0.73      0.70       131