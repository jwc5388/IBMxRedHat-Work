import pandas as pd
import numpy as np
import os
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
from keras.models import Sequential, load_model
from keras.layers import LSTM, Dense, Dropout, BatchNormalization
from keras.callbacks import ModelCheckpoint, EarlyStopping
from datetime import datetime

# --- 1. ê²½ë¡œ ì„¤ì • ---
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
SAVE_DIR = f'/workspace/TensorJae/Study25/_save/jena/{timestamp}/'
os.makedirs(SAVE_DIR, exist_ok=True)

DATA_PATH = '/workspace/TensorJae/Study25/_data/jena_climate_2009_2016.csv'
MODEL_SAVE_PATH = os.path.join(SAVE_DIR, 'best_model.h5')
SUBMISSION_PATH = os.path.join(SAVE_DIR, 'submission.csv')

# --- 2. ë°ì´í„° ë¡œë”© ë° êµ¬ê°„ ì •ì˜ ---
TIMESTEPS = 144  # 1ì¼ì¹˜ ë°ì´í„° (144 * 10ë¶„)
df = pd.read_csv(DATA_PATH, parse_dates=['Date Time'])

start_pred = pd.to_datetime("31.12.2016 00:10:00", dayfirst=True)
end_pred = pd.to_datetime("01.01.2017 00:00:00", dayfirst=True)

# âœ… [ìˆ˜ì •] ë¯¸ë˜ ë°ì´í„° ëˆ„ìˆ˜ í•´ê²°
# ì˜ˆì¸¡ ì‹œì‘ ì‹œì  ì´ì „ì˜ ë°ì´í„°ë§Œ í›ˆë ¨/ê²€ì¦ ë°ì´í„°ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
df_train_val = df[df['Date Time'] < start_pred].copy()
df_to_predict = df[(df['Date Time'] >= start_pred) & (df['Date Time'] <= end_pred)].copy()

# --- 3. Feature ì„¤ì • ë° ìˆœí™˜ì„± ë³€í™˜ ---
feature_columns = [col for col in df.columns if col not in ['Date Time', 'wd (deg)']]
target_column = 'wd (deg)'

def deg_to_sin_cos(deg):
    rad = np.deg2rad(deg)
    return np.sin(rad), np.cos(rad)

df_train_val['wd_sin'], df_train_val['wd_cos'] = deg_to_sin_cos(df_train_val[target_column])

# --- 4. ì •ê·œí™” ---
scaler = StandardScaler().fit(df_train_val[feature_columns])
df_train_val_scaled = df_train_val.copy()
df_train_val_scaled[feature_columns] = scaler.transform(df_train_val[feature_columns])

# --- 5. ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ìƒì„± ---
def split_xy(x, y1, y2, timesteps):
    x_seq, y1_seq, y2_seq = [], [], []
    for i in range(len(x) - timesteps):
        x_seq.append(x[i:i+timesteps])
        y1_seq.append(y1[i+timesteps])
        y2_seq.append(y2[i+timesteps])
    return np.array(x_seq), np.array(y1_seq), np.array(y2_seq)

x_data = df_train_val_scaled[feature_columns].values
y_sin_data = df_train_val['wd_sin'].values
y_cos_data = df_train_val['wd_cos'].values

# âœ… [ìˆ˜ì •] stride=6 ìœ¼ë¡œ ì„¤ì • (1ì‹œê°„ ê°„ê²© ìƒ˜í”Œë§)
x, y_sin, y_cos = split_xy(x_data, y_sin_data, y_cos_data, TIMESTEPS)
y = np.stack([y_sin, y_cos], axis=1) # y ë°ì´í„°ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹¨

# --- 6. í•™ìŠµ/ê²€ì¦ ë¶„ë¦¬ (ì‹œê°„ ìˆœì„œ) ---
split_idx = int(len(x) * 0.9) # 90% í›ˆë ¨, 10% ê²€ì¦
x_train, x_val = x[:split_idx], x[split_idx:]
y_train, y_val = y[:split_idx], y[split_idx:]

# --- 7. ëª¨ë¸ ì •ì˜ ---
model = Sequential([
    LSTM(64, input_shape=(x.shape[1], x.shape[2]), return_sequences=True),
    LSTM(64, return_sequences=False),
    BatchNormalization(),
    Dense(64, activation='relu'),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dense(2, activation='tanh')  # sin, cos ë‘ ê°œ ì˜ˆì¸¡
])
model.compile(optimizer='adam', loss='mse', metrics=['mae'])
model.summary()

# --- 8. í•™ìŠµ ---
# âœ… EarlyStopping ì¶”ê°€
es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
checkpoint = ModelCheckpoint(MODEL_SAVE_PATH, monitor='val_loss', save_best_only=True, verbose=1)

model.fit(x_train, y_train,
          validation_data=(x_val, y_val),
          epochs=50, batch_size=64, callbacks=[es, checkpoint], verbose=1)

# --- 9. ì˜ˆì¸¡ ë°ì´í„° ì¤€ë¹„ ---
# ì˜ˆì¸¡ì„ ìœ„í•´, ë§ˆì§€ë§‰ í›ˆë ¨ ë°ì´í„°(TIMESTEPS ë§Œí¼)ì™€ ì˜ˆì¸¡í•  êµ¬ê°„ì˜ ë°ì´í„°ë¥¼ í•©ì¹©ë‹ˆë‹¤.
last_train_data = df_train_val.tail(TIMESTEPS)
concat_for_pred = pd.concat([last_train_data, df_to_predict], ignore_index=True)

# ì •ê·œí™” ì ìš©
concat_for_pred_scaled = concat_for_pred.copy()
concat_for_pred_scaled[feature_columns] = scaler.transform(concat_for_pred[feature_columns])
x_pred_data = concat_for_pred_scaled[feature_columns].values

# ì˜ˆì¸¡í•  ì‹œí€€ìŠ¤ ìƒì„±
x_pred = []
# ì „ì²´ ê¸¸ì´ì—ì„œ TIMESTEPSë¥¼ ëº€ ë§Œí¼ë§Œ ë°˜ë³µí•˜ë©´ ì •í™•íˆ ì˜ˆì¸¡ ëŒ€ìƒ ê¸°ê°„ì˜ ìƒ˜í”Œì´ ìƒì„±ë¨
for i in range(len(x_pred_data) - TIMESTEPS):
    x_pred.append(x_pred_data[i:i+TIMESTEPS])
x_pred = np.array(x_pred)

# --- 10. ì˜ˆì¸¡ ìˆ˜í–‰ ---
best_model = load_model(MODEL_SAVE_PATH)
y_pred_sin_cos = best_model.predict(x_pred)

# --- 11. ì˜ˆì¸¡ ê²°ê³¼ ë³µì› ë° í‰ê°€ ---
def sincos_to_deg(sin_vals, cos_vals):
    radians = np.arctan2(sin_vals, cos_vals)
    degrees = np.rad2deg(radians)
    return (degrees + 360) % 360  # ìŒìˆ˜ ê°ë„ ë³´ì •

y_pred_deg = sincos_to_deg(y_pred_sin_cos[:, 0], y_pred_sin_cos[:, 1])
y_true_deg = df_to_predict[target_column].values

rmse = np.sqrt(mean_squared_error(y_true_deg, y_pred_deg))
mae = mean_absolute_error(y_true_deg, y_pred_deg)

print("\n" + "="*50)
print("ğŸ“Œ ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ í‰ê°€")
print(f"ğŸ“ˆ RMSE: {rmse:.4f}")
print(f"ğŸ“ˆ MAE : {mae:.4f}")
print("="*50 + "\n")

# --- 12. ì €ì¥ ---
submission_df = pd.DataFrame({
    'Date Time': df_to_predict['Date Time'],
    'wd (deg)': y_pred_deg
})
submission_df.to_csv(SUBMISSION_PATH, index=False)
print(f"âœ… submission ì €ì¥ ì™„ë£Œ: {SUBMISSION_PATH}")
print(submission_df.head())


# ğŸ“ˆ RMSE: 59.2611
# ğŸ“ˆ MAE : 41.7753


# ğŸ“ˆ RMSE: 68.4766
# ğŸ“ˆ MAE : 45.6391

# ğŸ“ˆ RMSE: 70.7903
# ğŸ“ˆ MAE : 42.0439

# ğŸ“ˆ RMSE: 59.7079
# ğŸ“ˆ MAE : 38.8619


# ğŸ“ˆ RMSE: 53.7864
# ğŸ“ˆ MAE : 35.0676

# ğŸ“Œ ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ í‰ê°€
# ğŸ“ˆ RMSE: 65.3606
# ğŸ“ˆ MAE : 42.8297
# ====================