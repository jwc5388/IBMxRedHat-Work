import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.model_selection import train_test_split
import xgboost as xgb
import lightgbm as lgb
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from joblib import dump


# ê²½ë¡œ ì„¤ì •
if os.path.exists('/workspace/TensorJae/Study25/'):
    BASE_PATH = '/workspace/TensorJae/Study25/'
else:
    BASE_PATH = os.path.expanduser('~/Desktop/IBM:RedHat/Study25/')

path = os.path.join(BASE_PATH, '_data/stocks/')
samsung = pd.read_csv(path + 'samsung.csv', thousands=',')
hanwha = pd.read_csv(path + 'hanwha.csv', thousands=',')
hanwha = hanwha.rename(columns={'Unnamed: 6': 'ëŒ€ë¹„_ê¸ˆì•¡'})

# ì•¡ë©´ë¶„í•  ë³´ì • í•¨ìˆ˜
def cut(df):
    df = df.copy()
    df['ì¼ì'] = pd.to_datetime(df['ì¼ì'], dayfirst=True)
    df = df.sort_values(by='ì¼ì', ascending=False).dropna()
    split_date = pd.to_datetime('2018-05-04')
    split_ratio = 50
    price_cols = ['ì‹œê°€', 'ê³ ê°€', 'ì €ê°€', 'ì¢…ê°€']
    df.loc[df['ì¼ì'] < split_date, price_cols] = df.loc[df['ì¼ì'] < split_date, price_cols] / split_ratio
    return df

samsung = cut(samsung)
hanwha = cut(hanwha)

# ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess(df):
    df = df.copy()
    df['ì¼ì'] = pd.to_datetime(df['ì¼ì'], dayfirst=True)
    df = df.sort_values(by='ì¼ì', ascending=False).dropna()
    df['ì‹œê°€_5ì¼_MA'] = df['ì‹œê°€'].rolling(window=5).mean()
    df['ì‹œê°€_ë³€í™”'] = df['ì‹œê°€'].diff()
    df['ë“±ë½ë¥ _1ì¼ì „'] = df['ì‹œê°€'].pct_change() * 100
    df['target'] = df['ì‹œê°€'].shift(-1)
    # print(df['ì¼ì'].head(10))
    df = df.dropna()
    X = df.drop(columns=['ì¼ì', 'target', 'ëŒ€ë¹„'])
    y = df['target']
    latest_x = X.iloc[0]
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    latest_x_scaled = scaler.transform([latest_x.values])[0]
    return X_scaled, y, latest_x_scaled, scaler

# ì „ì²˜ë¦¬
xh, yh, xh_latest, scaler_h = preprocess(hanwha)
xs, ys, xs_latest, scaler_s = preprocess(samsung)

# í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
xh_train, xh_test, yh_train, yh_test = train_test_split(xh, yh, train_size=0.8, shuffle=False)
xs_train, xs_test, ys_train, ys_test = train_test_split(xs, ys, train_size=0.8, shuffle=False)

# í•œí™” ëª¨ë¸ í•™ìŠµ
model_h = XGBRegressor(n_estimators=300, random_state=42)
model_h.fit(xh_train, yh_train)
pred_h_train = model_h.predict(xh_train)

# ì‚¼ì„±ìœ¼ë¡œ ì”ì°¨ ì˜ˆì¸¡
residuals = yh_train - pred_h_train
model_residual = XGBRegressor(n_estimators=300, random_state=42)
model_residual.fit(xs_train[:len(residuals)], residuals)

#============================================================================================
yh_pred_test = model_h.predict(xh_test)
rmse = np.sqrt(mean_squared_error(yh_test, yh_pred_test))
mae = mean_absolute_error(yh_test, yh_pred_test)
print("\nğŸ“Š í•œí™” ë‹¨ë… ëª¨ë¸ ì„±ëŠ¥ ")
print(f" - RMSE: {rmse:,.2f}")
print(f" - MAE : {mae:,.2f}")

residual_test = model_residual.predict(xs_test[:len(yh_test)])
ensemble_pred_test = yh_pred_test + residual_test
rmse_ensemble = np.sqrt(mean_squared_error(yh_test, ensemble_pred_test))
mae_ensemble = mean_absolute_error(yh_test, ensemble_pred_test)
print("\nğŸ“Š âœ… ì”ì°¨ ê¸°ë°˜ ì•™ìƒë¸” ì„±ëŠ¥")
print(f" - RMSE: {rmse_ensemble:,.2f}")
print(f" - MAE : {mae_ensemble:,.2f}")

#============================================================================================

# ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ê°€ì¤‘ì¹˜ ì €ì¥
save_path = os.path.join(path, '_save/')
os.makedirs(save_path, exist_ok=True)
dump(model_h, os.path.join(save_path, 'model_h.joblib'))
dump(model_residual, os.path.join(save_path, 'model_residual.joblib'))
dump(scaler_h, os.path.join(save_path, 'scaler_h.joblib'))
dump(scaler_s, os.path.join(save_path, 'scaler_s.joblib'))
print(f"\nâœ… ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ê°€ì¤‘ì¹˜ ì €ì¥ ì™„ë£Œ! â†’ {save_path}")

#ìµœì¢… ì˜ˆì¸¡
pred_h_latest = model_h.predict([xh_latest])[0]
residual_latest = model_residual.predict([xs_latest])[0]
final_pred = pred_h_latest + residual_latest
print("\nğŸ“ˆ 2025ë…„ 7ì›” 14ì¼ ì‹œê°€ ì˜ˆì¸¡")
print(f" - í•œí™” ë‹¨ë… ì˜ˆì¸¡     : {int(pred_h_latest):,} ì›")
print(f" - ì‚¼ì„± ê¸°ë°˜ ì”ì°¨ ë³´ì •: {int(residual_latest):,} ì›")
print(f" âœ… ìµœì¢… ë³´ì • ì˜ˆì¸¡     : {int(final_pred):,} ì›")


# ==============================================================================
# [ì¶”ê°€] ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” íŒŒíŠ¸
# ==============================================================================
# plt.figure(figsize=(15, 7))

# # yh_test.indexë¥¼ ì‚¬ìš©í•´ ì‹œê°„ì˜ íë¦„ì— ë”°ë¥¸ ì‹¤ì œ ì£¼ê°€ì™€ ì˜ˆì¸¡ ì£¼ê°€ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
# plt.plot(yh_test.index, yh_test, label='ì‹¤ì œ ì£¼ê°€ (Actual Price)', color='blue', linewidth=2)
# plt.plot(yh_test.index, ensemble_pred_test, label='ìµœì¢… ì˜ˆì¸¡ (Final Prediction)', color='red', linestyle='--', linewidth=2)
# # plt.plot(yh_test.index, yh_pred_test, label='ê¸°ë³¸ ì˜ˆì¸¡ (Base Prediction)', color='green', linestyle=':', linewidth=1) # ê¸°ë³¸ ì˜ˆì¸¡ê³¼ ë¹„êµí•˜ê³  ì‹¶ì„ ë•Œ ì£¼ì„ í•´ì œ

# plt.title('actual price vs. predicted price', fontsize=16)
# plt.xlabel('Time', fontsize=12)
# plt.ylabel('Price', fontsize=12)
# plt.legend(fontsize=12)
# plt.grid(True)
# plt.show()
# ==============================================================================