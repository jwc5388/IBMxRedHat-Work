
import os
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import StackingRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error
from xgboost import XGBRegressor
from catboost import CatBoostRegressor
from lightgbm import LGBMRegressor
import random
import tensorflow as tf
import datetime

# Seed ê³ ì •
seed = 33
random.seed(seed)
np.random.seed(seed)
tf.random.set_seed(seed)

# ê²½ë¡œ ì„¤ì •
if os.path.exists('/workspace/TensorJae/Study25/'):
    BASE_PATH = '/workspace/TensorJae/Study25/'
else:
    BASE_PATH = os.path.expanduser('~/Desktop/IBM:RedHat/Study25/')

path = os.path.join(BASE_PATH, '_data/dacon/electricity/')
save_path = os.path.join(path, '_save/')

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
buildinginfo = pd.read_csv(path + 'building_info.csv')
train = pd.read_csv(path + 'train.csv')
test = pd.read_csv(path + 'test.csv')
samplesub = pd.read_csv(path + 'sample_submission.csv')

# ê²°ì¸¡ì¹˜ ì²˜ë¦¬: '-' â†’ 0, float ë³€í™˜
cols_to_clean = ['íƒœì–‘ê´‘ìš©ëŸ‰(kW)', 'ESSì €ì¥ìš©ëŸ‰(kWh)', 'PCSìš©ëŸ‰(kW)']
for col in cols_to_clean:
    buildinginfo[col] = buildinginfo[col].replace('-', 0).astype(float)

# ë‚ ì§œ íŒŒì‹± ë° íŒŒìƒë³€ìˆ˜
for df in [train, test]:
    df['ì¼ì‹œ'] = pd.to_datetime(df['ì¼ì‹œ'])
    df['hour'] = df['ì¼ì‹œ'].dt.hour
    df['dayofweek'] = df['ì¼ì‹œ'].dt.dayofweek

# ê±´ë¬¼ ì •ë³´ ë³‘í•©
train = train.merge(buildinginfo, on='ê±´ë¬¼ë²ˆí˜¸', how='left')
test = test.merge(buildinginfo, on='ê±´ë¬¼ë²ˆí˜¸', how='left')

# ë²”ì£¼í˜• ì²˜ë¦¬
train['ê±´ë¬¼ìœ í˜•'] = train['ê±´ë¬¼ìœ í˜•'].astype('category').cat.codes
test['ê±´ë¬¼ìœ í˜•'] = test['ê±´ë¬¼ìœ í˜•'].astype('category').cat.codes

# í”¼ì²˜ ì„¤ì •
test_features = ['ê±´ë¬¼ë²ˆí˜¸', 'ê±´ë¬¼ìœ í˜•', 'ì—°ë©´ì (m2)', 'ëƒ‰ë°©ë©´ì (m2)', 'íƒœì–‘ê´‘ìš©ëŸ‰(kW)',
                 'ESSì €ì¥ìš©ëŸ‰(kWh)', 'PCSìš©ëŸ‰(kW)', 'ê¸°ì˜¨(Â°C)', 'ê°•ìˆ˜ëŸ‰(mm)', 'í’ì†(m/s)',
                 'ìŠµë„(%)', 'hour', 'dayofweek']
target = 'ì „ë ¥ì†Œë¹„ëŸ‰(kWh)'

# í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
x = train[test_features]
y = np.log1p(train[target])
x_test_final = test[test_features]

x_train, x_val, y_train, y_val = train_test_split(x, y, train_size=0.8, random_state=seed)

# ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_val_scaled = scaler.transform(x_val)
x_test_final_scaled = scaler.transform(x_test_final)

# ëª¨ë¸ ì •ì˜
xgb = XGBRegressor(n_estimators=600, learning_rate=0.1, max_depth=6, random_state=seed)
lgb = LGBMRegressor(n_estimators=600, learning_rate=0.1, max_depth=6, random_state=seed)
cat = CatBoostRegressor(n_estimators=600, learning_rate=0.1, max_depth=6, random_state=seed, verbose=0)

stack_model = StackingRegressor(
    estimators=[
        ('xgb', xgb),
        ('lgb', lgb),
        ('cat', cat),
    ],
    final_estimator=GradientBoostingRegressor(n_estimators=350, random_state=seed),
    n_jobs=-1
)

# í•™ìŠµ
stack_model.fit(x_train_scaled, y_train)

# ì˜ˆì¸¡ (ë¡œê·¸ ë³µì›)
y_pred = np.expm1(stack_model.predict(x_val_scaled))
y_true = np.expm1(y_val)

# SMAPE ê³„ì‚°
def smape(y_true, y_pred):
    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true)))

print(f"\nâœ… ê²€ì¦ SMAPE: {smape(y_true, y_pred):.4f}")

# ì œì¶œ
# ì˜ˆì¸¡ ë° ë¡œê·¸ ë³µì›
final_pred = np.expm1(stack_model.predict(x_test_final_scaled))
samplesub['answer'] = final_pred

# ì˜¤ëŠ˜ ë‚ ì§œ
today = datetime.datetime.now().strftime('%Y%m%d')

# ê²€ì¦ SMAPE ì ìˆ˜ ê³„ì‚°
val_smape = smape(y_true, y_pred)
score_str = f"{val_smape:.4f}".replace('.', '_')

# íŒŒì¼ëª… ìƒì„±
filename = f"submission_{today}_SMAPE_{score_str}.csv"
file_path = os.path.join(path, filename)

# ì €ì¥
samplesub.to_csv(file_path, index=False)
print(f"ğŸ“ {filename} ì €ì¥ ì™„ë£Œ!")
