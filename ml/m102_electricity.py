# import os
# import pandas as pd
# import numpy as np
# from sklearn.preprocessing import StandardScaler
# from sklearn.model_selection import train_test_split
# from sklearn.ensemble import StackingRegressor, GradientBoostingRegressor
# from sklearn.metrics import mean_absolute_error
# from xgboost import XGBRegressor
# from catboost import CatBoostRegressor
# from lightgbm import LGBMRegressor
# import random
# import tensorflow as tf

# # ê³ ì • ì‹œë“œ
# seed = 42
# random.seed(seed)
# np.random.seed(seed)
# tf.random.set_seed(seed)

# # ê²½ë¡œ ì„¤ì •
# if os.path.exists('/workspace/TensorJae/Study25/'):
#     BASE_PATH = '/workspace/TensorJae/Study25/'
# else:
#     BASE_PATH = os.path.expanduser('~/Desktop/IBM:RedHat/Study25/')

# path = os.path.join(BASE_PATH, '_data/dacon/electricity/')
# save_path = os.path.join(path, '_save/')

# # ë°ì´í„° ë¡œë“œ
# buildinginfo = pd.read_csv(path + 'building_info.csv')
# train = pd.read_csv(path + 'train.csv')
# test = pd.read_csv(path + 'test.csv')
# samplesubmission = pd.read_csv(path + 'sample_submission.csv')

# # ë‚ ì§œ íŒŒì‹± ë° ì‹œê°„/ìš”ì¼ íŒŒìƒë³€ìˆ˜ ì¶”ê°€
# for df in [train, test]:
#     df['ì¼ì‹œ'] = pd.to_datetime(df['ì¼ì‹œ'])
#     df['hour'] = df['ì¼ì‹œ'].dt.hour
#     df['dayofweek'] = df['ì¼ì‹œ'].dt.dayofweek

# # building_infoì˜ '-' ê°’ì„ ê²°ì¸¡ì¹˜ë¡œ ì²˜ë¦¬ í›„ float ë³€í™˜
# for col in ['íƒœì–‘ê´‘ìš©ëŸ‰(kW)', 'ESSì €ì¥ìš©ëŸ‰(kWh)', 'PCSìš©ëŸ‰(kW)']:
#     buildinginfo[col] = pd.to_numeric(buildinginfo[col].replace('-', np.nan))

# # train/testì— building_info ë³‘í•©
# train = train.merge(buildinginfo, on='ê±´ë¬¼ë²ˆí˜¸', how='left')
# test = test.merge(buildinginfo, on='ê±´ë¬¼ë²ˆí˜¸', how='left')

# # ë²”ì£¼í˜• -> ìˆ«ìí˜• ë³€í™˜
# for df in [train, test]:
#     df['ê±´ë¬¼ìœ í˜•'] = df['ê±´ë¬¼ìœ í˜•'].astype('category').cat.codes

# # ê³µí†µ feature ì •ì˜ (test ê¸°ì¤€)
# test_features = ['ê±´ë¬¼ë²ˆí˜¸', 'ê±´ë¬¼ìœ í˜•', 'ì—°ë©´ì (m2)', 'ëƒ‰ë°©ë©´ì (m2)', 'íƒœì–‘ê´‘ìš©ëŸ‰(kW)',
#                  'ESSì €ì¥ìš©ëŸ‰(kWh)', 'PCSìš©ëŸ‰(kW)', 'ê¸°ì˜¨(Â°C)', 'ê°•ìˆ˜ëŸ‰(mm)', 'í’ì†(m/s)',
#                  'ìŠµë„(%)', 'hour', 'dayofweek']

# # train featureëŠ” 'ì¼ì¡°(hr)', 'ì¼ì‚¬(MJ/m2)' í¬í•¨ë˜ë¯€ë¡œ ë”°ë¡œ ì •ì˜
# train_features = test_features + ['ì¼ì¡°(hr)', 'ì¼ì‚¬(MJ/m2)']
# target = 'ì „ë ¥ì†Œë¹„ëŸ‰(kWh)'

# x = train[train_features]
# y = train[target]
# x_test_final = test[test_features]

# # ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°
# x = x.fillna(0)
# x_test_final = x_test_final.fillna(0)

# # í•™ìŠµ/ê²€ì¦ ë¶„ë¦¬
# x_train, x_val, y_train, y_val = train_test_split(x, y, train_size=0.8, random_state=seed)

# # ìŠ¤ì¼€ì¼ë§ (test featureì— ë§ì¶°ì„œë§Œ ì ìš©)
# scaler = StandardScaler()
# x_train_scaled = scaler.fit_transform(x_train[test_features])
# x_val_scaled = scaler.transform(x_val[test_features])
# x_test_final_scaled = scaler.transform(x_test_final)

# # ë¶€ìŠ¤íŒ… ëª¨ë¸ ì •ì˜
# xgb_model = XGBRegressor(n_estimators=200, learning_rate=0.1, max_depth=6, random_state=seed)
# lgb_model = LGBMRegressor(n_estimators=200, learning_rate=0.1, max_depth=6, random_state=seed)
# cat_model = CatBoostRegressor(n_estimators=200, learning_rate=0.1, max_depth=6, random_state=seed, verbose=0)

# # ìŠ¤íƒœí‚¹ ì•™ìƒë¸” ì •ì˜
# stack_model = StackingRegressor(
#     estimators=[
#         ('xgb', xgb_model),
#         ('lgb', lgb_model),
#         ('cat', cat_model),
#     ],
#     final_estimator=GradientBoostingRegressor(n_estimators=100, random_state=seed),
#     n_jobs=-1
# )

# # ëª¨ë¸ í•™ìŠµ
# stack_model.fit(x_train_scaled, y_train)

# # ê²€ì¦ ì˜ˆì¸¡ ë° SMAPE
# val_pred = stack_model.predict(x_val_scaled)
# def smape(y_true, y_pred):
#     denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0
#     diff = np.abs(y_true - y_pred) / denominator
#     diff[denominator == 0] = 0.0
#     return np.mean(diff) * 100

# print(f"âœ… ê²€ì¦ SMAPE: {smape(y_val, val_pred):.4f}")

# # í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ í›„ ì œì¶œ
# final_pred = stack_model.predict(x_test_final_scaled)
# samplesubmission['answer'] = final_pred
# filename = f"submission_stack_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv"
# samplesubmission.to_csv(os.path.join(path, filename), index=False)
# print(f"ğŸ“ ì €ì¥ ì™„ë£Œ â†’ {filename}")


import os
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import StackingRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error
from xgboost import XGBRegressor
from catboost import CatBoostRegressor
from lightgbm import LGBMRegressor
import random
import tensorflow as tf
import datetime

# Seed ê³ ì •
seed = 42
random.seed(seed)
np.random.seed(seed)
tf.random.set_seed(seed)

# ê²½ë¡œ ì„¤ì •
if os.path.exists('/workspace/TensorJae/Study25/'):
    BASE_PATH = '/workspace/TensorJae/Study25/'
else:
    BASE_PATH = os.path.expanduser('~/Desktop/IBM:RedHat/Study25/')

path = os.path.join(BASE_PATH, '_data/dacon/electricity/')
save_path = os.path.join(path, '_save/')

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
buildinginfo = pd.read_csv(path + 'building_info.csv')
train = pd.read_csv(path + 'train.csv')
test = pd.read_csv(path + 'test.csv')
samplesub = pd.read_csv(path + 'sample_submission.csv')

# ê²°ì¸¡ì¹˜ ì²˜ë¦¬: '-' â†’ 0, float ë³€í™˜
cols_to_clean = ['íƒœì–‘ê´‘ìš©ëŸ‰(kW)', 'ESSì €ì¥ìš©ëŸ‰(kWh)', 'PCSìš©ëŸ‰(kW)']
for col in cols_to_clean:
    buildinginfo[col] = buildinginfo[col].replace('-', 0).astype(float)

# ë‚ ì§œ íŒŒì‹± ë° íŒŒìƒë³€ìˆ˜
for df in [train, test]:
    df['ì¼ì‹œ'] = pd.to_datetime(df['ì¼ì‹œ'])
    df['hour'] = df['ì¼ì‹œ'].dt.hour
    df['dayofweek'] = df['ì¼ì‹œ'].dt.dayofweek

# ê±´ë¬¼ ì •ë³´ ë³‘í•©
train = train.merge(buildinginfo, on='ê±´ë¬¼ë²ˆí˜¸', how='left')
test = test.merge(buildinginfo, on='ê±´ë¬¼ë²ˆí˜¸', how='left')

# ë²”ì£¼í˜• ì²˜ë¦¬
train['ê±´ë¬¼ìœ í˜•'] = train['ê±´ë¬¼ìœ í˜•'].astype('category').cat.codes
test['ê±´ë¬¼ìœ í˜•'] = test['ê±´ë¬¼ìœ í˜•'].astype('category').cat.codes

# í”¼ì²˜ ì„¤ì •
test_features = ['ê±´ë¬¼ë²ˆí˜¸', 'ê±´ë¬¼ìœ í˜•', 'ì—°ë©´ì (m2)', 'ëƒ‰ë°©ë©´ì (m2)', 'íƒœì–‘ê´‘ìš©ëŸ‰(kW)',
                 'ESSì €ì¥ìš©ëŸ‰(kWh)', 'PCSìš©ëŸ‰(kW)', 'ê¸°ì˜¨(Â°C)', 'ê°•ìˆ˜ëŸ‰(mm)', 'í’ì†(m/s)',
                 'ìŠµë„(%)', 'hour', 'dayofweek']
target = 'ì „ë ¥ì†Œë¹„ëŸ‰(kWh)'

# í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
x = train[test_features]
y = np.log1p(train[target])
x_test_final = test[test_features]

x_train, x_val, y_train, y_val = train_test_split(x, y, train_size=0.8, random_state=seed)

# ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_val_scaled = scaler.transform(x_val)
x_test_final_scaled = scaler.transform(x_test_final)

# ëª¨ë¸ ì •ì˜
xgb = XGBRegressor(n_estimators=600, learning_rate=0.1, max_depth=6, random_state=seed)
lgb = LGBMRegressor(n_estimators=600, learning_rate=0.1, max_depth=6, random_state=seed)
cat = CatBoostRegressor(n_estimators=600, learning_rate=0.1, max_depth=6, random_state=seed, verbose=0)

stack_model = StackingRegressor(
    estimators=[
        ('xgb', xgb),
        ('lgb', lgb),
        ('cat', cat),
    ],
    final_estimator=GradientBoostingRegressor(n_estimators=350, random_state=seed),
    n_jobs=-1
)

# í•™ìŠµ
stack_model.fit(x_train_scaled, y_train)

# ì˜ˆì¸¡ (ë¡œê·¸ ë³µì›)
y_pred = np.expm1(stack_model.predict(x_val_scaled))
y_true = np.expm1(y_val)

# SMAPE ê³„ì‚°
def smape(y_true, y_pred):
    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true)))

print(f"\nâœ… ê²€ì¦ SMAPE: {smape(y_true, y_pred):.4f}")

# ì œì¶œ
# ì˜ˆì¸¡ ë° ë¡œê·¸ ë³µì›
final_pred = np.expm1(stack_model.predict(x_test_final_scaled))
samplesub['answer'] = final_pred

# ì˜¤ëŠ˜ ë‚ ì§œ
today = datetime.datetime.now().strftime('%Y%m%d')

# ê²€ì¦ SMAPE ì ìˆ˜ ê³„ì‚°
val_smape = smape(y_true, y_pred)
score_str = f"{val_smape:.4f}".replace('.', '_')

# íŒŒì¼ëª… ìƒì„±
filename = f"submission_{today}_SMAPE_{score_str}.csv"
file_path = os.path.join(path, filename)

# ì €ì¥
samplesub.to_csv(file_path, index=False)
print(f"ğŸ“ {filename} ì €ì¥ ì™„ë£Œ!")