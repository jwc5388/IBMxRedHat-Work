# === inference.py ===
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import r2_score
from pathlib import Path

# -----------------------
# 0) Device
# -----------------------
DEVICE = (
    torch.device('cuda') if torch.cuda.is_available()
    else torch.device('mps') if torch.backends.mps.is_available()
    else torch.device('cpu')
)
print('torch:', torch.__version__, 'ì‚¬ìš© DEVICE:', DEVICE)

# -----------------------
# 1) ê²½ë¡œ ì„¤ì •
# -----------------------
# ë„¤ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •
DATA_DIR = Path('/Users/jaewoo000/Desktop/IBM:RedHat/Study25/_data/kaggle/netflix/')
SAVE_DIR = Path('/Users/jaewoo000/Desktop/IBM:RedHat/Study25/_save/torch/')
WEIGHT_PATH = SAVE_DIR / 't25_netflix.pth'   # ì €ì¥í•´ë‘” ê°€ì¤‘ì¹˜ íŒŒì¼

TRAIN_CSV = DATA_DIR / 'train.csv'
TEST_CSV  = DATA_DIR / 'test.csv'
SUB_CSV   = DATA_DIR / 'sample_submission.csv'  # ìˆìœ¼ë©´ ì œì¶œ í˜•ì‹ìœ¼ë¡œ ì €ì¥ ì‹œ í™œìš©

# -----------------------
# 2) Dataset (í›ˆë ¨ ê¸°ì¤€ min/maxë¡œ ì •ê·œí™”)
# -----------------------
class SlidingDataset(Dataset):
    """
    df: DataFrame (train or test)
    x_cols: ì…ë ¥ ì—´ ì¸ë±ìŠ¤ ëª©ë¡ ë˜ëŠ” ì»¬ëŸ¼ëª… ëª©ë¡ (ì—¬ê¸°ì„œëŠ” df.iloc[:, 1:4] ì‚¬ìš© ê°€ì •)
    y_col: íƒ€ê¹ƒ ì»¬ëŸ¼ëª… (train ì „ìš©). testì—ëŠ” None ê°€ëŠ¥.
    timesteps: ì‹œê³„ì—´ ìœˆë„ ê¸¸ì´
    x_min, x_max: í›ˆë ¨ì…‹ì—ì„œ êµ¬í•œ ì—´ë³„ min/max (ì •ê·œí™” ê¸°ì¤€)
    """
    def __init__(self, df, x_cols, y_col=None, timesteps=30, x_min=None, x_max=None):
        self.timesteps = timesteps

        if isinstance(x_cols, slice):
            X = df.iloc[:, x_cols].values.astype(np.float32)
        else:
            X = df.loc[:, x_cols].values.astype(np.float32)

        if x_min is None or x_max is None:
            # í›ˆë ¨ì…‹ìš©: ë‚´ë¶€ì—ì„œ fit
            self.x_min = X.min(axis=0)
            self.x_max = X.max(axis=0)
        else:
            # í…ŒìŠ¤íŠ¸ì…‹ìš©: í›ˆë ¨ì…‹ ê¸°ì¤€ì„ ì™¸ë¶€ì—ì„œ ì£¼ì…
            self.x_min = x_min
            self.x_max = x_max

        denom = (self.x_max - self.x_min)
        denom[denom == 0.0] = 1.0  # ë¶„ëª¨ 0 ë°©ì–´
        X = (X - self.x_min) / denom

        self.X = X
        self.y = None
        if y_col is not None and y_col in df.columns:
            self.y = df[y_col].values.astype(np.float32)

        # ìœ íš¨ ê¸¸ì´
        self.N = len(self.X) - self.timesteps
        if self.N < 1:
            raise ValueError(f"í–‰ ê°œìˆ˜({len(self.X)})ê°€ timesteps({self.timesteps})ë³´ë‹¤ ì‘ì•„ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¥¼ ë§Œë“¤ ìˆ˜ ì—†ìŒ.")

    def __len__(self):
        return self.N

    def __getitem__(self, idx):
        x = self.X[idx : idx + self.timesteps]  # (T, F)
        x = torch.from_numpy(x)
        if self.y is None:
            return x, None
        y = self.y[idx + self.timesteps]        # ë‹¤ìŒ ì‹œì 
        return x, torch.tensor(y, dtype=torch.float32)

# -----------------------
# 3) ëª¨ë¸ ì •ì˜ (í›ˆë ¨ ì‹œì™€ ë™ì¼ êµ¬ì¡°)
# -----------------------
class RNN(nn.Module):
    def __init__(self, input_size=3, hidden_size=64, num_layers=3):
        super().__init__()
        self.rnn = nn.RNN(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
        )
        self.fc1 = nn.Linear(hidden_size, 32)
        self.fc2 = nn.Linear(32, 1)
        self.relu = nn.ReLU()

    def forward(self, x):
        x, _ = self.rnn(x)     # (B, T, H)
        x = x[:, -1, :]        # (B, H)
        x = self.relu(self.fc1(x))
        x = self.fc2(x)
        return x.squeeze(1)    # (B,)

# -----------------------
# 4) ë¡œë“œ + í‰ê°€/ì˜ˆì¸¡
# -----------------------
def main():
    timesteps = 30
    batch_size = 64

    # 4-1) ë°ì´í„° ë¡œë“œ
    train_df = pd.read_csv(TRAIN_CSV)
    test_df  = pd.read_csv(TEST_CSV)

    # ì…ë ¥ íŠ¹ì„±: ì—´ 1~3 (ì˜ˆ: Open, High, Low) ê°€ì •
    x_cols = slice(1, 4)
    y_col  = 'Close'  # íƒ€ê¹ƒ

    # 4-2) í›ˆë ¨ì…‹ ê¸°ì¤€ ì •ê·œí™” íŒŒë¼ë¯¸í„° ì¶”ì¶œ
    tmp_train = SlidingDataset(train_df, x_cols=x_cols, y_col=y_col, timesteps=timesteps)
    x_min, x_max = tmp_train.x_min.copy(), tmp_train.x_max.copy()

    # ì •ì‹ Dataset/DataLoader
    train_ds = SlidingDataset(train_df, x_cols=x_cols, y_col=y_col, timesteps=timesteps,
                              x_min=x_min, x_max=x_max)
    test_ds  = SlidingDataset(test_df,  x_cols=x_cols, y_col=None,   timesteps=timesteps,
                              x_min=x_min, x_max=x_max)

    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False, drop_last=False)
    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, drop_last=False)

    # 4-3) ëª¨ë¸ ë¡œë“œ
    model = RNN(input_size=3, hidden_size=64, num_layers=3).to(DEVICE)
    state = torch.load(WEIGHT_PATH, map_location=DEVICE)
    model.load_state_dict(state)
    model.eval()

    # 4-4) í›ˆë ¨ì…‹ í‰ê°€(MSE, RÂ²)
    criterion = nn.MSELoss()
    total_loss = 0.0
    y_pred_all, y_true_all = [], []

    with torch.no_grad():
        for xb, yb in train_loader:
            xb = xb.to(DEVICE).float()
            yb = yb.to(DEVICE).float()
            pred = model(xb)
            total_loss += criterion(pred, yb).item()
            y_pred_all.append(pred.cpu().numpy())
            y_true_all.append(yb.cpu().numpy())

    y_pred = np.concatenate(y_pred_all)
    y_true = np.concatenate(y_true_all)
    r2 = r2_score(y_true, y_pred)

    print(f'âœ… Train í‰ê°€ - í‰ê·  MSE: {total_loss / len(train_loader):.6f}')
    print(f'âœ… Train í‰ê°€ - RÂ²: {r2:.6f}')

    # 4-5) í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡
    test_preds = []
    with torch.no_grad():
        for xb, _ in test_loader:
            xb = xb.to(DEVICE).float()
            pred = model(xb)
            test_preds.append(pred.cpu().numpy())
    test_preds = np.concatenate(test_preds).reshape(-1)

    # 4-6) ì €ì¥: sample_submissionê³¼ ê¸¸ì´ ë§ì¶”ê¸°
    # ìŠ¬ë¼ì´ë”© ìœˆë„ìš° íŠ¹ì„±ìƒ ì˜ˆì¸¡ ê°œìˆ˜ = len(test) - timesteps
    # sample_submission ê¸¸ì´ì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë§ì¶°ì„œ ì €ì¥
    sub_path = DATA_DIR / 'sample_submission.csv'
    if sub_path.exists():
        sub = pd.read_csv(sub_path).copy()
        # ê¸¸ì´ ì¡°ì • ë¡œì§
        if len(test_preds) >= len(sub):
            sub['Close'] = test_preds[:len(sub)]
        else:
            # ë¶€ì¡±í•˜ë©´ ë’¤ë¥¼ ë§ˆì§€ë§‰ ê°’ìœ¼ë¡œ ì±„ì›€(ë˜ëŠ” NaN ì±„ì›€)
            pad = np.full(len(sub) - len(test_preds), test_preds[-1] if len(test_preds) > 0 else 0.0)
            sub['Close'] = np.concatenate([test_preds, pad])
        out_path = SAVE_DIR / 'submission_inference.csv'
        out_path.parent.mkdir(parents=True, exist_ok=True)
        sub.to_csv(out_path, index=False)
        print(f'ğŸ“ ì œì¶œ íŒŒì¼ ì €ì¥: {out_path}  (shape={sub.shape})')
    else:
        # ìƒ˜í”Œ ì œì¶œ íŒŒì¼ì´ ì—†ë‹¤ë©´, ì˜ˆì¸¡ë§Œ ë³„ë„ ì €ì¥
        out_path = SAVE_DIR / 'test_predictions_sliding.csv'
        out_path.parent.mkdir(parents=True, exist_ok=True)
        pd.DataFrame({'pred': test_preds}).to_csv(out_path, index=False)
        print(f'ğŸ“ í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ì €ì¥: {out_path}  (len={len(test_preds)})')

if __name__ == "__main__":
    main()